trainer:
  devices: [0]
  mxp: true
  run_eagerly: false
  batch_size: 4
  epochs: 20
  workers: 8
  max_queue_size: 8 # TODO: what is the optimal value? batch size * n?
  use_multiprocessing: true
  log_interval: 100
  checkpoint:
    filepath: outputs/tensorflow/checkpoints/rnnt_{epoch:02d}.h5
    save_best_only: true
    save_weights_only: false
    save_freq: epoch
  states_dir: outputs/tensorflow/rnnt_20200218_01/states
  tensorboard:
    log_dir: outputs/tensorflow/rnnt_20200218_01/logs
    histogram_freq: 1
    write_graph: true
    write_images: true
    update_freq: 10
    profile_batch: 2

spec_augment:
  freq_masks: 2
  time_masks: 2
  freq_width: 15
  time_width: 25

train_ds:
  stage: train
  data_paths:
    - /workspace/datasets/tensorflow_asr.tsv
  shuffle: true
  cache: true
  buffer_size: 100
  drop_remainder: true
  num_print_sample_data: 1

validation_ds:
  stage: val
  data_paths:
    - /workspace/datasets/tensorflow_asr_val.tsv
  shuffle: false
  cache: true
  buffer_size: 100
  drop_remainder: true

audio_feature:
  sample_rate: 16000
  window_size: 0.02
  window_stride: 0.01
  n_mels: &n_mels 80
  preemph: 0.97
  dither: 1e-5
  pad_to: 8

text_feature:
  vocabulary: null
  target_vocab_size: 1024 # 16,384
  max_subword_length: 4 # 20
  blank_at_zero: true
  beam_width: 5
  norm_score: true
  subwords: /workspace/datasets/subwords.subwords # Path to file that stores generated subwords
  subwords_corpus: # Transcript files for generating subwords
    - /workspace/datasets/tensorflow_asr.tsv

optimizer:
  name: adam
  learning_rate: 0.0005
  beta_1: 0.9
  beta_2: 0.999
 
  lr_scheduler:
    _target_: optimizers.lr_scheduler.WarmupCosineAnnealing
    warmup_ratio: 0.05
    warmup_learning_rate: 1e-6

  variational_noise:
    mean: 0
    stddev: 0.075
    start_step: -1

encoder:
  _target_: modules.rnnt_encoder.RNNTEncoder
  dim_model: 320
  num_units: 1024
  num_layers: 8
  reduction_indices: [0, 1]
  reduction_factors: [3, 2]

predictor:
  _target_: modules.transducer_predictor.TransducerPredictor
  num_layers: 2
  embed_dim: 320
  dim_model: 1024
  random_state_sampling: true

joint:
  _target_: modules.transducer_joint.TransducerJoint
  dim_model: 320
  activation: tanh

tflite:
  model_path: tflites/rnnt.tflite