trainer:
  epochs: 100
  max_queue_size: 10
  use_multiprocessing: false
  workers: 1
  run_eagerly: true
  model_checkpoint:
    filepath: tensorflow_checkpoints
    save_best_only: true
  tensorboard:
    log_dir: tensorflow_outputs
  precision:
    name: mixed_float16

labels:
  [
    " ",
    "a",
    "b",
    "c",
    "d",
    "e",
    "f",
    "g",
    "h",
    "i",
    "j",
    "k",
    "l",
    "m",
    "n",
    "o",
    "p",
    "q",
    "r",
    "s",
    "t",
    "u",
    "v",
    "w",
    "x",
    "y",
    "z",
    "'",
  ]

train_ds:
  # tfrecord dataset
  stage: train
  batch_size: 4
  tfrecords_dir: ../datasets
  tfrecords_shards: 16
  cache: true
  shuffle: true
  num_samples: 2703

  # manifest
  sample_rate: 16000
  manifest_filepath: ../datasets/manifest_val.json # TODO: just for now
  max_duration: null
  min_duration: null
  normalize_transcripts: false # lowercase
  
  # augment
  augmentor:
    speed:
      prob: 1.0
      sr: 16000

validation_ds:
  # tfrecord dataset
  stage: val
  batch_size: 4
  tfrecords_dir: ../datasets
  tfrecords_shards: 2
  cache: true
  shuffle: false
  num_samples: 2703

  # manifest
  sample_rate: 16000
  manifest_filepath: ../datasets/manifest_val.json # for google colab
  max_duration: null
  min_duration: null
  normalize_transcripts: false # lowercase

preprocessor:
  _target_: frontends.audio_preprocess.AudioToMelSpectrogramPreprocessor
  sample_rate: 16000
  window_size: 0.02
  window_stride: 0.01
  n_mels: &n_mels 80
  preemph: 0.97
  dither: 1e-5
  pad_to: 16

inference:
  _target_: modules.greedy_inference.GreedyInference
  max_symbols_per_step: 30

stream:
  _target_: modules.stream.EmformerStream

spec_augment:
  _target_: frontends.spec_augment.SpectrogramAugmentation
  freq_masks: 2
  time_masks: 2
  freq_width: 15
  time_width: 25

encoder:
  _target_: modules.emformer_encoder.EmformerEncoder

  feat_in: *n_mels
  num_layers: 16 # 26 for medium latency, 18 for low latency in paper
  num_heads: 8
  dim_model: 512
  dim_ffn: 2048
  dropout_attn: 0.1

  subsampling: vgg # frame stacking in paper
  subsampling_factor: 4
  subsampling_dim: 256 

  left_length: 20 # 800ms / (4 stacked frames x 10ms per frame)
  chunk_length: 32 # 1280ms / (4 stacked frames x 10ms per frame)
  right_length: 8 # 320ms / (4 stacked frames x 10ms per frame)

predictor:
  _target_: modules.transducer_predictor.TransducerPredictor
  num_layers: 1 # 2 in paper
  embed_dim: 320 # 256 in paper
  dim_model: 320 # 512 in paper
  random_state_sampling: true

joint:
  _target_: modules.transducer_joint.TransducerJoint
  dim_model: 320 # 640 in paper
  activation: tanh

optimizer:
  name: adam
  learning_rate: 0.0005
  beta_1: 0.9
  beta_2: 0.999

  lr_scheduler:
    _target_: optimizers.lr_scheduler.WarmupCosineAnnealing
    warmup_ratio: 0.05
    warmup_learning_rate: 1e-6

postprocessor:
  log_every_n_steps: 10
  gradient_clip_val: 1
  variational_noise:
    mean: 0
    std: 0.075
    start_step: -1
