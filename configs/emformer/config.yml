encoder:
  _target_: rnnt_encoder.RNNTEncoder
  dim_model: 320
  num_units: 1024
  num_layers: 8
  reduction_indices: [0, 1]
  reduction_factors: [3, 2]

predictor:
  _target_: transducer_predictor.TransducerPredictor
  num_layers: 2
  embed_dim: 320
  dim_model: 1024
  random_state_sampling: true

joint:
  _target_: transducer_joint.TransducerJoint
  dim_model: 320
  activation: tanh

trainer:
  devices: [0]
  mxp: true
  run_eagerly: true
  batch_size: 4
  epochs: 20
  checkpoint:
    filepath: outputs/tensorflow_asr/checkpoints/{epoch:02d}.h5
    save_best_only: true
    save_weights_only: false
    save_freq: epoch
  states_dir: outputs/tensorflow_asr/states
  tensorboard:
    log_dir: outputs/tensorflow_asr
    histogram_freq: 1
    write_graph: true
    write_images: true
    update_freq: epoch
    profile_batch: 2

spec_augment:
  freq_masks: 2
  time_masks: 2
  freq_width: 15
  time_width: 25

train_ds:
  stage: train
  use_tf: true
  data_paths:
    - /workspace/datasets/tensorflow_asr.tsv
  shuffle: true
  cache: true
  buffer_size: 100
  drop_remainder: true

validation_ds:
  stage: val
  use_tf: true
  data_paths:
    - /workspace/datasets/tensorflow_asr_val.tsv
  shuffle: false
  cache: true
  buffer_size: 100
  drop_remainder: true

audio_feature:
  sample_rate: 16000
  window_size: 0.02
  window_stride: 0.01
  n_mels: &n_mels 80
  preemph: 0.97
  dither: 1e-5
  pad_to: 8

decoder_config:
  vocabulary: null
  target_vocab_size: 1024 # 16,384
  max_subword_length: 4 # 40
  blank_at_zero: true
  beam_width: 5
  norm_score: true

optimizer:
  name: adam
  # learning_rate: 0.0005
  beta_1: 0.9
  beta_2: 0.999

  # for quick debugging
  learning_rate: 0.0001
 
  # lr_scheduler:
  #   _target_: lr_scheduler.WarmupCosineAnnealing
  #   warmup_ratio: 0.05
  #   warmup_learning_rate: 1e-6


 
subwords: /workspace/datasets/subwords.subwords # Path to file that stores generated subwords
subwords_corpus: # Transcript files for generating subwords
  - /workspace/datasets/tensorflow_asr.tsv